[DEFAULT]
; this is the path to where the cosebis files are kept
cosebis_path = /path/to/cosebis/
; path to the main folder where all the outputs will be written
outputDirectory= /path/to/output/
; path to cosmosis-standard-library
cosmosis_standrad_library_path=/path/to/standard/library/
; COSEBIs inputs:
tmin=0.5 ; minimum theta
tmax=250.0 ; maximum theta
nmax=20 ; number of modes from 1 to nmax
inputCovName=%(cosebis_path)s/DESy1Inputs/CEnMixed_Th_FromInputNpair_weighted_DES_y1_20_0.50-250.00_1.ascii ; input covariance for calculating the likelihood
inputEnName=%(cosebis_path)s/DESy1Inputs/En_20_0.50-250.00_1.ascii ; input En from data
; multiple bins
;nz_file_name=y1_redshift_distributions_v1.fits
; one bin
nz_file_name=DES-y1_mcal_1bin.fits ; input n(z)

[runtime]
; The test sampler just runs a single parameter set
sampler = emcee

; The output section describes where to save the results of the sampling. Not all samplers use this facility - for example, the test and maxlike samplers produce only a single value and so do not need an output file. 
[output]
filename = %(outputDirectory)s/LikelihoodAnalysis/cosebis_emcee_KV450_IA_6params_05_72.txt
format = text
verbosity= highest
; verbosity	Choose from "silent", "quiet", "gentle", "standard", "noisy", "debug", and "highest" to get different amounts of output. Not all the printing code uses this mechanism so we need to improve it.

; The total number of samples taken is walkers*samples.
; Running a sampler in parallel
; To run a sampler in parallel you must have mpi4py installed
; this means you must also have an MPI environment including mpicc and mpif90 (the automatic installation includes all these).
; For all the samplers, you can run in parallel on, e.g. four samplers, like this:
; mpirun -n 4 cosmosis --mpi params.ini
; Maximum process numbers
; For emcee, the most MPI processes you can use without having some idle is nwalkers/2+1.

[emcee]
; The emcee sampler uses the concept of walkers, a collection
; of live points.  Sampling is done along lines that connect
; pairs of walkers.  The number of walkers must be at least
; 2*nparam + 1, but in general more than that usually works
; better.
;The total number of samples taken is walkers*samples.
walkers = 48
samples = 1500
; This is the interval at which convergence diagnostics
; are performed
nsteps = 100
;start_points=cosmosis-standard-library/cosebis/values.ini


[test]
save_dir=%(outputDirectory)s/COSEBIS_predictions/
fatal_errors=T

; The pipeline section contains information
; that describes the sequence of calculations
; to be done and what we want out at the end
[pipeline]
quiet = T
timing = F
debug = F
modules = consistency camb halofit growth extrapolate fits_nz source_photoz_bias  IA ia_z_field pk_to_cl add_intrinsic shear_m_bias cosebis_likelihood
values = %(cosebis_path)s/DESy1Inputs/values_likelihood.ini
;priors = %(cosebis_path)s/prior.ini

likelihoods = cosebis
extra_output = 


[consistency]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/utility/consistency/consistency_interface.py

[camb]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/boltzmann/camb/camb.so
mode = all
lmax = 2500
feedback = 0
kmin = 1e-5
kmax = 10.0
nk = 200


[halofit_takahashi]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/boltzmann/halofit_takahashi/halofit_interface.so
nk = 700

;dont think this makes a difference!
[growth]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/structure/growth_factor/interface.so
zmin = 0.
zmax = 4.
nz = 401

[extrapolate]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/boltzmann/extrapolate/extrapolate_power.py
kmax = 500.

; need to fix this it is looking for nz_"data_sets" 
[fits_nz]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/number_density/load_nz_fits/load_nz_fits.py
nz_file = %(cosebis_path)s/DESy1Inputs/%(nz_file_name)s
data_sets = source_mcal
prefix_section = T
prefix_extension = T

[source_photoz_bias]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_source_mcal
bias_section = wl_photoz_errors
interpolation = linear


[IA]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/intrinsic_alignments/la_model/linear_alignments_interface.py
do_galaxy_intrinsic = F
method = bk_corrected
;method: "string, choice of 'bk', 'bk_corrected', 'krhb', chooses which model to run"
;  A number of variations to the LA model have been discussed since, and this module
; implements three of them.  The history is a little convoluted as an error was found
; in early work missing a factor of (1+z), so one of our models is a corrected version
; of one of the other ones.  Our models are:
;         Bridle & King
;         Bridle & King (corrected)
;         Kirk, Rassat, Host, Bridle

[ia_z_field]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/intrinsic_alignments/z_powerlaw/ia_z_powerlaw.py
do_galaxy_intrinsic = F


[pk_to_cl]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/structure/projection/project_2d.py
ell_min = 0.1
ell_max = 5.0e5
n_ell = 400
position-shear = F
shear-shear = source_mcal-source_mcal
position-position = F
intrinsic-intrinsic = source_mcal-source_mcal
shear-intrinsic = source_mcal-source_mcal
position-intrinsic = F
verbose = F
get_kernel_peaks = F

[add_intrinsic]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/shear/add_intrinsic/add_intrinsic.py
shear-shear = T
perbin = F
position-shear = F

[shear_m_bias]
file = %(cosmosis_standrad_library_path)s/cosmosis-standard-library/shear/shear_bias/shear_m_bias.py
m_per_bin = True
verbose = F

[cosebis_likelihood]
file = %(cosebis_path)s/libcosebis_likelihood.so
theta_min = %(tmin)s
theta_max = %(tmax)s
n_max = %(nmax)s
input_cosebis_filename = %(inputEnName)s
input_covariance_filename = %(inputCovName)s

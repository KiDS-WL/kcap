[DEFAULT]
; this is the path to where the input files are kept
;input_path = /path/to/2pcfs/
input_path = /Users/marika_asgary/Documents/CosmicShear/repos/cosebis_cosmosis/
; path to the main folder where all the outputs will be written
;outputDirectory= /path/to/output/
outputDirectory = %(input_path)s/example_files/outputs/
; path to cosmosis-standard-library
;cosmosis_standrad_library_path=/path/to/cosmosis/standard/library/
cosmosis_standrad_library_path=/Users/marika_asgary/Documents/CosmicShear/repos/kcap/cosmosis-standard-library/

inputCovName=%(input_path)s/example_files/covariance.ascii ; input covariance for calculating the likelihood
input2PCFsName=%(input_path)s/example_files/xipm_data.ascii; input 2PCFs from data
nz_file_name=nofz.fits ; input n(z)
redshift_name = flinc

[runtime]
; The test sampler just runs a single parameter set
sampler = test

; The output section describes where to save the results of the sampling. Not all samplers use this facility - for example, the test and maxlike samplers produce only a single value and so do not need an output file. 
[output]
filename = %(outputDirectory)s/outputs/test_output.txt
format = text
verbosity= highest
; verbosity	Choose from "silent", "quiet", "gentle", "standard", "noisy", "debug", and "highest" to get different amounts of output. Not all the printing code uses this mechanism so we need to improve it.

; The total number of samples taken is walkers*samples.
; Running a sampler in parallel
; To run a sampler in parallel you must have mpi4py installed
; this means you must also have an MPI environment including mpicc and mpif90 (the automatic installation includes all these).
; For all the samplers, you can run in parallel on, e.g. four samplers, like this:
; mpirun -n 4 cosmosis --mpi params.ini
; Maximum process numbers
; For emcee, the most MPI processes you can use without having some idle is nwalkers/2+1.

[emcee]
; The emcee sampler uses the concept of walkers, a collection
; of live points.  Sampling is done along lines that connect
; pairs of walkers.  The number of walkers must be at least
; 2*nparam + 1, but in general more than that usually works
; better.
;The total number of samples taken is walkers*samples.
walkers = 48
samples = 1500
; This is the interval at which convergence diagnostics
; are performed
nsteps = 100
;start_points=cosmosis-standard-library/cosebis/values.ini


[test]
save_dir=%(outputDirectory)s/outputs/
fatal_errors=T

; The pipeline section contains information
; that describes the sequence of calculations
; to be done and what we want out at the end
[pipeline]
quiet = T
timing = F
debug = F
modules = consistency camb halofit_takahashi extrapolate fits_nz pk_to_cl cl2xi pcfs
values = %(input_path)s/example_files/values_likelihood.ini


likelihoods = pcfs
extra_output = 


[consistency]
file = %(cosmosis_standrad_library_path)s/utility/consistency/consistency_interface.py


[camb]
file = %(cosmosis_standrad_library_path)s/boltzmann/camb/camb.so
mode=all
lmax=2500
;accuracy_boost = 2.0
;high_accuracy_default = T
feedback=0
kmin=1e-5
kmax=10.0
nk=200
zmax=6.0
zmin=0.0
;nz=2
background_zmax=6.0
background_zmin=0.0
background_nz=150


[halofit_takahashi]
file = %(cosmosis_standrad_library_path)s/boltzmann/halofit_takahashi/halofit_interface.so


[extrapolate]
file = %(cosmosis_standrad_library_path)s/boltzmann/extrapolate/extrapolate_power.py
kmax = 500.


[fits_nz]
file = %(cosmosis_standrad_library_path)s/number_density/load_nz_fits/load_nz_fits.py
nz_file = %(input_path)s/example_files/%(nz_file_name)s
data_sets = %(redshift_name)s
prefix_section = T
prefix_extension = T

[pk_to_cl]
file = %(cosmosis_standrad_library_path)s/structure/projection/project_2d.py
ell_min = 0.1
ell_max = 5.0e5
n_ell = 400
position-shear = F
shear-shear = %(redshift_name)s-%(redshift_name)s 
position-position = F
intrinsic-intrinsic = F
shear-intrinsic = F
position-intrinsic = F
verbose = F
get_kernel_peaks = F


[cl2xi]
file = %(cosmosis_standrad_library_path)s/shear/cl_to_xi_nicaea/nicaea_interface.so
corr_type = 0

; There are differenet inputs you can give for this
[pcfs]
file = %(input_path)s/lib2pcfs_likelihood.so
output_section_name= pcfs ; the DEFAULT is pcfs
input_section_name_plus =shear_xi_plus ; the DEFAULT is shear_xi_plus
input_section_name_minus =shear_xi_minus ; the DEFAULT is shear_xi_minus
;; With these ones no weighted binning is done for the theory
theta_plus_file_name = theta_plus_file.ascii; a file with theta_plus values if it doesn't exist 
; will look for theta_min_plus, theta_max_plus and nTheta_plus then do log binning between min and max.
; if the file exists we will ignore theta_min_plus,theta_max_plus and nTheta_plus
theta_min_plus=0.5
theta_max_plus=72.40262468
nTheta_plus=7
;
theta_minus_file_name=theta_minus_file.ascii; a file with theta_minus values if it doesn't exist 
; will look for theta_min_minus, theta_max_minus and nTheta_minus then do log binning between min and max.
; if the file exists we will ignore theta_min_minus,theta_max_minus and nTheta_minus
theta_min_minus=4.21716333
theta_max_minus=300.0
nTheta_minus=6

;;if you want weighted binning you need to at least give the bin edges in a file
; if these files are given then we will ignore the theta values above
theta_min_max_plus_filename = theta_plus_bin_edges_file.ascii ; these are the edges of the theta plus bins,
theta_min_max_minus_filename = theta_minus_bin_edges_file.ascii ; these are the edges for the theta minus bins

; if InputNpair not given weighted binning is set to theta
InputNpair= InputNpair; a file containing the number of npair per finely binned thetas.
Column_theta = 0 ; which column in the file is theta? default is 0
Column_Npair = 7 ; which column in the file is npair? default is 7
nBins = 5 ; number of redshift bins, this needs to be given, otherwise will set weighted binning to just theta

; the data file that is already binned the same way as the theory is going to be. 
; So the input theta files or values have to match this.
input_2pcfs_filename=%(input2PCFsName)s
; The input covariance file, which should also match the thetas of the data vector.
input_covariance_filename = %(inputCovName)s
; Here we assume that the ordering of the data vector is:
; ///The data vector format should be:
; // \xi_+^{11}(\theta_1)
; // \xi_+^{11}(\theta_2)
; // ...
; // \xi_+^{11}(\theta_max)
; // \xi_+^{nn}(\theta_1)
; // ...
; // \xi_+^{nn}(\theta_max)
; // \xi_-^{11}(\theta_1)
; // \xi_-^{11}(\theta_2)
; // ...
; // \xi_-^{11}(\theta_max)
; // ...
; // \xi_-^{nn}(\theta_1)
; // ...
; // \xi_-^{nn}(\theta_max)

InputXipm_2D_cterm = 2D_cterm.ascii; if not given just ignores the 2D 2D_cterm
; these two are needed to apply the constant c-term for xi_m, you can get using treecor or athena
; needs more documentation here, check if the following is right
; read in xi_pm files with Athena format. These are files created using a constant c1 and c2 catalouge with the
; same positions as the catalouge to be analysed. 
; Simply swap the epsilon_1 and epsilon_2 in your input cats with c1 and c2 respectively. 
; Do this for two sets of c1 and c2 so that the code can calculate sum (cos 4phi) and sum (sin 4phi) from the xi_mimus
; component. This is used for the constant c-term modelling which affects xi_minus given 
; a finite number of galaxies and  a finite field. 
; The important part is that the first three columns are
; theta xi_plus xi_minus
InputCos4phi = InputCos4phi.ascii; if not given doesn't apply a constant c-term
InputSin4phi = InputSin4phi.ascii; if not given doesn't apply a constant c-term


